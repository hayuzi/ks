Kafka基本应用
==

### 1.基本概念讲解

#### 1.1 基本的概念

- 消息和批次
    - 数据可以单条发送，也可以分批次写入Kafka
- 主题和分区的概念
    - Kafka的消息通过主题来进行分类.
    - 主题可以分为若干个分区，一个分区就是一个提交日志，消息以追加的方式写入分区，然后以先入先出的顺序读取
    - 无法在整个主题范围内保证消息的顺序，但是可以保证消息在单个分区内的顺序
    - Kafka通过分区来实现数据冗余和伸缩性
- 生产者
    - 生产者在默认情况下把消息均衡地分布到主题的所有分区上，并不关心特定消息会被写到哪个分区
    - 但是在某些情况下，生产者会把消息直接写入到指定的分区
    - 可以通过消息键和分区器来实现，分区器为键生成一个散列值，并将其映射到指定的分区上（保证同一个键的消息写到同一个分区上）
    - 生产者也可以使用自定义的分区器
- 消费者与偏移量
    - 消费者通过检查消息的偏移量来区分已经读过的消息
    - 偏移量是一个不断递增的整数值，在创建消息时候，Kafka会把他添加到消息里，在给定分区里，每个消息的偏移量都是唯一的
    - 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，消费者的关闭重启，他的读取状态不会丢失
- 消费者群组
    - 一个或者多个消费者共同读取一个主题
    - 群组保证每个分区只能被一个消费者使用
    - 消费者和分区之间的映射通常称为消费者对分区的所有权关系
    - 如果一个消费者失效，群组里面的其他消费者可以接管失效消费者的工作
    - 同一个消费群组在单个top下的消费者数量超出分区数量，超出的数量不会收到任何消息
- broker
    - 一个独立的Kafka服务器称为一个broker
    - broker为消息设置偏移量并提交消息到磁盘保存
    - broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息
    - 根据特定的硬件和其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级别的消息量
    - 需要多少broker
        - broker的磁盘空间（考虑复制系数）
        - 集群处理请求的能力（与网络接口处理客户端流量的能力有关）
- 集群
    - broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群活跃成员中选取）
    - 控制器负责管理，包括将分区分配给broker和监控broker
    - 在集群中，一个分区从属于一个broker，该broker被称为分区的首领
    - 一个分区可以分配给多个broker，这个时候会发生分区复制（一个broker失效，其他broker可以接管领导权，但相关消费者和生产者都要重新连接到新首领）
- 保留消息
    - Kafka默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留消息达到一定大小的字节数（比如1GB）
    - 当消息数量达到这些上限时，旧的消息就会过期并删除
    - 所以在任何时刻，可用消息的总量都不会超过配置参数所指定的大小
    - 另外：主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止
- 多集群
    - 基于数据类型分离、安全需求隔离、多数据中心（灾难恢复）等原因，最好使用多个集群
    - 多数据中心需要在他们之间复制消息
    - Kafka的消息复制机制只能在单个集群进行
    - Kafka提供了一个叫做MirrorMaker的工具，可以用它来实现集群之间的消息复制
    - MirrorMaker的核心组件包含了一个消费者和一个生产者，消费者从一个集群读取消息，生产者把消息发送到另外一个集群上

#### 1.2 Kafka的优势

- 多个生产者
- 多个消费者
    - kafka支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响。
    - 其他队列系统：消息一旦被一个客户端读取，其他客户端就无法再读取它。 **需要注意区别**
- 基于磁盘的数据存储
- 伸缩性
- 高性能
    - 横向扩展后，在处理大量数据的同时，还能保证亚秒级别的消息延迟
- 数据生态系统

#### 1.3 使用的一些问题

- 当一个broker上有很多的topic并且流量上来之后，会因为topic数量过多导致磁盘的顺序写退化为随机写，从而影响性能
- 使用短轮询方式，实时性取决于轮询间隔时间

### 2. 配置与调优

#### 2.1 配置

- broker配置
    - broker.id 和集群有关的配置
    - port 监听端口 默认9092
    - zookeeper.connect 保存元数据的zk地址（格式 hostname:port/path;hostname2:port2/path2）
    - log.dirs （格式 dir1;dir2;dir3）
    - num.recovery.threads.per.data.dir (多个线程有助于服务器包含大量分区时候的恢复加载)
- topic配置
    - num.partitions 分区数量
        - 分区数量依据 吞吐消息量来确定
    - log.retention.ms 数据保留的时间（ms、bytes只要一个条件满足即触发数据删除）
    - log.retention.bytes 数据保留的大小上限
    - log.segment.bytes 日志片段的大小上限（ms、bytes只要一个条件满足即触发片段关闭）
    - log.segment.ms 日志片段持续的时间上限，达到上限会被关闭
    - message.max.bytes
        - broker通过该参数限制单个消息的大小
        - 默认值 1000000（1M，压缩后的消息大小）
        - 消费者fetch.message.max.bytes或者集群broker中replica.fetch.max.bytes需要大于该参数，否则会导致消费消息阻塞

#### 2.2 硬件与性能

- 磁盘吞吐量
    - 多个磁盘以设置多目录、磁盘阵列、固态硬盘等可以提升Kafka的吞吐量
- 磁盘容量
    - 限制磁盘的消息堆积
- 内存
    - 页面缓存的使用可以增加吞吐率
    - 如果有消费者及时消费，消息会在页面缓存的时候就被读取消费
    - 不建议把kafka同其他重要应用程序部署在一起
- 网络
    - 网络吞吐量决定了Kafka能够处理的最大数据流量
    - 它和磁盘存储是制约Kafka扩展规模的主要因素
- CPU
    - 消息批量解压、设置偏移量、批量压缩、再保存会消耗CPU算力
    - 但不是组主要的限制

#### 2.3 集群的系统调优

- 虚拟内存
    - Kafka大量使用系统页面缓存
    - 相关配置
        - vm.swappiness
        - vm.dirty_background_ratio
        - vm.dirty_ratio
        - ```cat /proc/vmstat | egrep "dirty|writeback"```查看当前脏页的数量
- 磁盘
    - 选择合适的存储介质 (磁盘、固态硬盘)
    - 选择合适的文件系统
    - 对文件挂载点的noatime参数进行合理的设置（ 读取的atime参数不更新 ）
- 网络
    - socket读写缓冲区大小（合理值是 131072 也就是128KB）
        - net.core.wmem_default
        - net.core.rmem_default
    - socket读写缓冲区最大值（合理值是 2097152 也就是2MB）
        - net.core.wmem_max
        - net.core.rmem_max
    - TCP socket的读写缓冲区 (参数格式 "4096 65536 2097152" 分别为最小值、默认值、最大值)
        - net.ipv4.tcp_wmem
        - net.ipv4.tcp_rmem
    - net.ipv4.tcp_window_scaling 设置为 1，启用TCP时间窗扩展, 可以提升客户端传输数据的效率，传输的数据可以在服务器端上进行缓冲
    - net.ipv4.tcp_max_syn_backlog 设置为比默认值 1024更大的值，可以接受更多的并发连接（半连接队列大小）
    - net.core.netdev_max_backlog 设置为比默认值1000更大的值。有助于应对网络流量的爆发（当每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目，一般默认值为128）
    - net.core.somaxconn tcp全连接队列

### 3.集群原理

#### 3.1 集群成员关系

Kafka集群依赖zookeeper来维护集群成员信息

- 每个broker都有一个唯一标识符，这个标识符可以在配置文件指定，也可以自动生成
- broker在启动的时候，它通过创建**临时节点**把自己的ID注册到Zookeeper
- Kafka组件订阅Zookeeper的/brokers/ids路径（broker在zookeeper上注册的路径）
- 当有broker加入集群或者退出集群的时候，这些组件就可以获得通知
- 鉴于Zookeeper原理，如果启动另一个相同ID的broker，在Zookeeper上注册会失败
- broker停机、出现网络分区或长时间垃圾回收停顿时，broker会从Zookeeper上断开连接。这时候注册的临时节点会被从Zookeeper上移除。集群broker列表的Kafka组件会被告知该broker已经被移除

#### 3.2 控制器

- 就是一个broker，只不过他还负责分区首领的选举
- 通过在zookeeper里创建临时节点 /controller让自己成为控制器。（ 只有一个节点会创建成功 ）
- 每一个broker加入都会有此尝试，控制器已经存在则 在 控制器节点上创建 Zookeeper watch对象，这样他们就可以收到这个节点的变动通知
- 如果控制器被关闭或者与zookeeper断开连接，则Zookeeper上的临时节点会消失，其他节点通过watch对象会得到通知
- 其他节点收到通知后，会尝试创建，进入到类似开始加入时候的控制器节点创建流程，重新选出一个控制器
- 每个新选出的控制器通过Zookeeper的条件递增操作获得一个全新的、数值更大的controller epoch.
- 其他broker在知道当前controller的epoch之后，如果收到由控制器发出的包含较旧的epoch消息，就会忽略他们

#### 3.3 复制

Kafka使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。那些副本被保存在broker上。每个broker可以保存成百上千个属于不同主题和分区的副本

副本类型：

- 首领副本
    - 每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本
- 跟随者副本
    - 首领副本以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求
    - 他们唯一的任务就是从首领副本那里复制消息，保持与首领一致的状态
    - 如果首领发生崩溃，其中一个跟随者会被提升为新首领

副本消息复制

- 跟随者向首领发送获取数据的请求，首领将响应消息发送给跟随者。请求消息里面包含了从副本想要获取的消息的偏移量，而且这些偏移量总是有序的
- 通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度
- 如果跟随者在10s哪没有请求任何消息，或者虽然在请求消息，但是10s内没有请求最新的数据，那么它就会被认为是不同步的。
- 如果一个副本无法与首领保持一致，在首领发生失效时候，他就不可能成为新首领（没包含全部消息）
- 持续请求得到的最新消息副本被称为同步副本，在首领发生失效时，只有同步副本才有可能被选为新首领

首选首领

- 除了当前首领外，每个分区都有一个首选首领----创建主题时选定的首领就是分区的首选首领
- 首选首领：在创建分区时，需要在broker之间均衡首领。因此我们希望首选首领成为真正的首领时，broker间的负载最终会得到均衡
- 默认情况下，Kafka的auto.leader.rebalance.enable为true，它会检查首选首领是不是当前首领，如果不是，并且该副本是同步的，那么就会触发首领选举，让首选首领当选

#### 3.4 处理请求

broker的服务模式

- broker会在他监听的每一个端口上运行一个Acceptor线程，这个线程会创建一个连接，并把它交给Processor线程去处理。
- Processor线程（也被叫做网络线程）的数量是可以配置的
- 网络线程负责从客户端获取请求消息，把它们放进请求队列，然后从响应队列获取响应消息，把他们发送给客户端
- 请求消息被放到请求队列后，IO线程 会负责处理他们

处理的副本：

- 生产请求和获取请求都必须发送给分区的首领副本
- 特定分区请求发送到非分区首领所在的broker上，客户端会得到一个错误响应。Kafka客户端需要自己负责把生产请求和获取请求发送到正确broker上

元数据请求

- 元数据请求包含了客户端感兴趣的主题列表
- 服务端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本，以及哪个副本是首领
- 元数据请求可以发送给任意一个broker，因为所有broker都缓存了这些消息
- 一般来说，客户端会缓存这些消息，并定期通过发送元数据请求来刷新这些信息，从而指知道数据是否发生了变更
- 如果客户端收到"非首领"错误，他会在尝试重发请求之前先刷新元数据

生产请求

- 包含首领副本的broker在收到生产请求的时候，会对请求做一些验证
    - 发送数据的用户是否有主题的写入权限
    - 请求里包含的acks值是否有效果（0，1，all）
        - 0 表示生产者能通过网络把消息发送出去即可
        - 1 表示首领副本收到消息并把它写入到分区数据文件时会返回确认或者错误响应（不一定同步到磁盘）
        - 如果acks=all,是否有足够多的同步副本保证消息已经被安全写入

- 之后消息写入本地磁盘**注意文件系统缓存**
    - 在Linux系统上，消息会被写到文件系统缓存里面，并不保证他们何时会被刷新到磁盘上
    - Kafka不会一直等待数据被写到磁盘上----**它依赖复制功能来保证消息的持久性**

获取请求

- 客户端请求要先达到执行的分区首领上，然后客户端通过检查元数据来确保请求的路由是正确的。
- 首领在收到请求时，会先检查请求是否有效
    - 比如，指定的偏移量在分区上是否存在
    - 如果客户端请求的是已经被删除的数据，或请求的偏移量不存在，那么broker将返回一个错误
- 如果请求偏移量存在，broker将按照客户端指定的数量上限从分区里面读消息，再把消息返回给客户端
    - 客户端除了设置消息数据上限，也可以设置下限，在数据积累到下限之后再发送给客户端（配合超时时间一起使用）
- 并不是所有保存在首领分区上的数据都可以被客户端读取到
    - 大部分客户端只能读取到已经被写入所有同步副本的消息
    - 这是为了保证崩溃一致性
- Kafka使用 **零拷贝** 技术向客户端发送消息
    - Kafka直接把消息从文件（或者更确切的说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区

其他请求

- kafka的broker内部交互的请求处理
- 早先版本偏移量保存在zookeeper，后来的版本偏移量保存在特定的topic，所以有了针对offset的操作请求
- 其他的请求等

#### 3.5 物理存储

Kafka基本存储单元是分区。分区无法在多个broker之间进行再细分，也无法在同一个broker的多个磁盘上进行再细分。 所以，分区的大小受到单个挂载点可用空间的限制

分区分配

- broker之间平均地分布分区副本
- 确保每个分区的每个副本分布在不同的broker上
- 如果为broker指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的broker上
- 具体分配流程此处暂不记录（）

文件管理

- 分区分成若干个片段（默认情况下，每个片段包含1GB或一周的数据，以较小的那个为准）。在broker向分区写入数据时，如果达到片段上限，就关闭当前文件，打开一个新的
- 正在写入数据的片段叫做 活跃片段。关闭的片段才可以删除
- broker会为分区里的每个片段打开一个文件句柄，哪怕片段是不活跃的。这样会导致打开过多的文件句柄，所以需要根据实际情况调优

文件格式

- Kafka消息和偏移量保存在文件里。保存在磁盘上的数据格式与从生产者发过来或者发送给消费者的消息格式是一样的。
- 使用相同格式消息进行磁盘存储和网络传输，Kafka可以使用零复制技术给消费者发送消息，同时避免对生产者已经压缩过的消息进行压缩和再压缩
- 除了键、值和偏移量外，消息里还包含了消息大小，校验和、消息格式版本号、压缩算法和时间戳

```
普通消息：
--------------------------------------------------------------------------------------------------
偏移量   魔术数   压缩和解压   时间戳  键的大小   键   值的大小       值（消息）
--------------------------------------------------------------------------------------------------

批量消息：（如下的包装消息包含了3个压缩过的消息）
--------------------------------------------------------------------------------------------------
                                            ｜ 偏移量 魔术数 压缩和解压 时间戳 键大小 键 值大小    值
                                            ------------------------------------------------------
偏移量   魔术数   压缩和解压   时间戳  值的大小  ｜ 偏移量 魔术数 压缩和解压 时间戳 键大小 键 值大小    值
                                            -----------------------------------------------------
                                            ｜ 偏移量 魔术数 压缩和解压 时间戳 键大小 键 值大小    值
--------------------------------------------------------------------------------------------------
```

索引

- 为了帮助broker能更快速地定位到指定的偏移量，Kafka为每个分区维护了一个索引
- 索引把偏移量映射到片段文件和偏移量在文件里的位置
- 索引也被分成片段，所以在删除消息时，也可以删除相应的索引。索引不存在或者删除，Kafka或通过重新读取消息并录制偏移量和位置来重新生成索引

清理

- 清理是一个独立概念，根据消息的键值对来为每个键保留最新的值，该键其他旧事件会被删除。
- 只有当应用程序生成的事件里包含了键值对时，为这些主题设置 compact 策略才有意义。如果主题包含null键，那么清理就会失败
- 如果Kafka启动时候启用了清理功能，每个broker会启动一个清理管理器线程和多个清理线程，来负责执行清理任务。这些线程会选择污浊率较高的分区进行清理
- 清理线程通过内存里的一个map来清理
    - map里的每个元素包含了消息键的散列值和消息的偏移量，键的散列值是16B加上偏移量共24B
    - 清理一个1GB的日志片段，假设每个消息大小为1KB，那么这个片段包含一百万个消息，而我们只要用24MB的map就可以清理这个片段
- 如果要删除所有key的消息，需要在这个key对应的发一个值为null的消息（墓碑消息）来标记删除，消费者获取到这个消息就知道意义了，在一定的事件后，墓碑消息可以被彻底删除
- 只在旧片段进行清理（compact）

### 4. 可靠数据传递

#### 4.1 可靠性保证

- 分区消息的顺序
- 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），他才被认为是已经提交的
    - 生产者可以选择接收不同类型的确认，比如在消息被完全提交时候的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时确认
- 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失
- 消费者只能读取已经提交的消息

#### 4.2 复制

- 主题 分区 副本 的复制机制 来保证可靠性
- 同步副本的认定条件（ 暂不记录 ）

#### 4.3 配置

- 复制系数
    - 主题级别是 replication.factor
    - broker级别是 default.replication.factor 默认是3
    - 复制系数的权衡
        - 更大的复制系数带来更高的可用性可靠性，更少的故障，但是占用的磁盘空间会按倍增长
        - 所以权衡业务的时候要考虑相关的场景均衡
    - 另外，副本分布也很重要
        - 机架配置参数 broker.rack

- 不完全的首领选举
    - unclean.leader.election 默认为true，只能在broker级别配置
    - 设置为true会允许 不同步副本成为首领（可能会有数据丢失风险）
    - false不允许 不同步副本成为首领（所有同步副本异常的时候，会导致服务不可用）
    - 需要根据具体的场景来选择

- 最少同步副本
    - 主题和broker级别上，都是min.insync.replicas
    - 这个值如果只有1的话，如果此同步副本异常，可能会导致数据异常
    - 如果当前可用的同步副本数量小于这个值的话，会导致数据不能写入

#### 4.4 生产者的可靠性

- 根据可靠性要求配置适当的acks值
- 配置生产者的重试次数
    - 生产者可以自动处理的错误和需要开发者手动处理的错误会分开
    - 可自动处理的，可以通过重试来解决 (注意重试机制可能导致消息重复创建)
- 额外错误处理
    - 额外的错误看业务是否需要补偿机制，针对性的做业务架构设计

#### 4.5 消费者的可靠性

- 偏移量提交
- 消费者可靠性配置
    - group.id 消费组机制
    - auto.offset.reset 指定了没有偏移量可以提交的时候或者请求的偏移量在broker上不存在的时候，消费者会做些什么
        - earliest 分区开头
        - latest 分区末尾
    - enable.auto.commit 是否自动提交偏移量
    - auto.commit.interval.ms 自动提交偏移量的间隔
- 显式提交偏移量
    - 处理完再提交
    - 提交频度是性能和重复消息数量之间的权衡
    - 确保对提交的偏移量心里有数
    - 再均衡问题需要考虑
    - 消费者可能需要重试
        - 处理异常最好不提交偏移量
        - 没处理好的数据放入缓冲区，并重试
        - 遇到可重试错误的时候，可以把错误消息写入一个独立主题，用其他消费者来消费（类似死信）
    - 消费者可能需要维护状态
        - 对消息流的多个消息的合并聚合统计等，需要自主去维护，建议使用专业工具或者类库
    - 长时间处理
        - 不能完全使用同步阻塞
        - 最好独立线程处理消息，独立线程维持心跳
    - 仅一次传递（幂等处理）核心是唯一性标识

#### 4.6 验证系统可靠性

- 配置验证
- 应用程序验证
- 生产环境监控

