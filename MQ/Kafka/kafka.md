Kafka基本应用
==

### 1.基本概念讲解

#### 1.1 基本的概念

- 消息和批次
    - 数据可以单条发送，也可以分批次写入Kafka
- 主题和分区的概念
    - Kafka的消息通过主题来进行分类.
    - 主题可以分为若干个分区，一个分区就是一个提交日志，消息以追加的方式写入分区，然后以先入先出的顺序读取
    - 无法在整个主题范围内保证消息的顺序，但是可以保证消息在单个分区内的顺序
    - Kafka通过分区来实现数据冗余和伸缩性
- 生产者
    - 生产者在默认情况下把消息均衡地分布到主题的所有分区上，并不关心特定消息会被写到哪个分区
    - 但是在某些情况下，生产者会把消息直接写入到指定的分区
    - 可以通过消息键和分区器来实现，分区器为键生成一个散列值，并旧爱更年期映射到指定的分区上（保证同一个键的消息写到同一个分区上）
    - 生产者也可以使用自定义的分区器
- 消费者与偏移量
    - 消费者通过检查消息的偏移量来区分已经读过的消息
    - 偏移量是一个不断递增的整数值，在创建消息时候，Kafka会把他添加到消息里，在给定分区里，每个消息的偏移量都是唯一的
    - 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，消费者的关闭重启，他的读取状态不会丢失
- 消费者群组
    - 一个或者多个消费者共同读取一个主题
    - 群组保证每个分区只能被一个消费者使用
    - 消费者和分区之间的映射通常称为消费者对分区的所有权关系
    - 如果一个消费者失效，群组里面的其他消费者可以接管失效消费者的工作
    - 同一个消费群组在单个top下的消费者数量超出分区数量，超出的数量不会收到任何消息
- broker
    - 一个独立的Kafka服务器称为一个broker
    - broker为消息设置偏移量并提交消息到磁盘保存
    - broker洧消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息
    - 根据特定的硬件和其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级别的消息量
    - 需要多少broker
        - broker的磁盘空间（考虑复制系数）
        - 集群处理请求的能力（与网络接口处理客户端流量的能力有关）
- 集群
    - broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群活跃成员中选取）
    - 控制器负责管理，包括将分区分配给broker和监控broker
    - 在集群中，一个分区从属于一个broker，该broker被称为分区的首领
    - 一个分区可以分配给多个broker，这个时候会发生分区复制（一个broker失效，其他broker可以接管领导权，但相关消费者和生产者都要重新连接到新首领）
- 保留消息
    - Kafka默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留消息达到一定大小的字节数（比如1GB）
    - 当消息数量达到这些上限时，旧的消息就会过期并删除
    - 所以在任何时刻，可用消息的总量都不会超过配置参数所指定的大小
    - 另外：主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止
- 多集群
    - 基于数据类型分离、安全需求隔离、多数据中心（灾难恢复）等原因，最好使用多个集群
    - 多数据中心需要在他们之间复制消息
    - Kafka的消息复制机制只能在单个集群进行
    - Kafka提供了一个叫做MirrorMaker的工具，可以用它来实现集群之间的消息复制
    - MirrorMaker的核心组件包含了一个消费者和一个生产者，消费者从一个集群读取消息，生产者把消息发送到另外一个集群上

#### 1.2 Kafka的优势

- 多个生产者
- 多个消费者
    - kafka支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响。
    - 其他队列队列系统：消息一旦被一个客户端读取，其他客户端就无法再读取它
- 基于磁盘的数据存储
- 伸缩性
- 高性能
    - 横向扩展后，在处理大量数据的同时，还能保证亚秒级别的消息延迟
- 数据生态系统

### 2. 配置与调优

#### 2.1 配置

- broker配置
    - broker.id 和集群有关的配置
    - port 监听端口 默认9092
    - zookeeper.connect 保存元数据的zk地址（格式 hostname:port/path;hostname2:port2/path2）
    - log.dirs （格式 dir1;dir2;dir3）
    - num.recovery.threads.per.data.dir (多个线程有助于服务器包含大量分区时候的恢复加载)
- topic配置
    - num.partitions 分区数量
        - 分区数量依据 吞吐消息量来确定
    - log.retention.ms 数据保留的时间（ms、bytes只要一个条件满足即触发数据删除）
    - log.retention.bytes 数据保留的大小上限
    - log.segment.bytes 日志片段的大小上限（ms、bytes只要一个条件满足即触发片段关闭）
    - log.segment.ms 日志片段持续的时间上限，达到上限会被关闭
    - message.max.bytes
        - broker通过该参数限制单个消息的大小
        - 默认值 1000000（1M，压缩后的消息大小）
        - 消费者fetch.message.max.bytes或者集群broker中replica.fetch.max.bytes需要大于该参数，负责会导致消费消息阻塞

#### 2.2 硬件与性能

- 磁盘吞吐量
    - 多个磁盘以设置多目录、磁盘阵列、固态硬盘等可以提升Kafka的吞吐量
- 磁盘容量
    - 限制磁盘的消息堆积
- 内存
    - 页面缓存的使用可以增加吞吐率
    - 如果有消费者及时消费，消息会在页面缓存的时候就被读取消费
    - 不建议吧kafka同其他重要应用程序部署在一起
- 网络
    - 网络吞吐量决定了Kafka能够处理的最大数据流量
    - 它和磁盘存储是制约Kafka扩展规模的主要因素
- CPU
    - 消息批量解压、设置偏移量、批量压缩、再保存会小号CPU算力
    - 但不是组主要的限制

#### 2.3 集群的系统调优

- 虚拟内存
    - Kafka大量使用系统页面缓存
    - 相关配置
        - vm.swappiness
        - vm.dirty_background_ratio
        - vm.dirty_ratio
        - ```cat /proc/vmstat | egrep "dirty|writeback"```查看当前脏页的数量
- 磁盘
    - 选择合适的存储介质 (磁盘、固态硬盘)
    - 选择合适的文件系统
    - 对文件挂载点的noatime参数进行合理的设置（ 读取的atime参数不更新 ）
- 网络
    - socket读写缓冲区大小（合理值是 131072 也就是128KB）
        - net.core.wmem_default
        - net.core.rmem_default
    - socket读写缓冲区最大值（合理值是 2097152 也就是2MB）
        - net.core.wmem_max
        - net.core.rmem_max
    - TCP socket的读写缓冲区 (参数格式 "4096 65536 2097152" 分别为最小值、默认值、最大值)
        - net.ipv4.tcp_wmem
        - net.ipv4.tcp_rmem
    - net.ipv4.tcp_window_scaling 设置为 1，启用TCP时间窗扩展, 可以提升客户端传输数据的效率，传输的数据可以在服务器端上进行缓冲
    - net.ipv4.tcp_max_syn_backlog 设置为比默认值 1024更大的值，可以接受更多的并发连接（半连接队列大小）
    - net.core.netdev_max_backlog 设置为比默认值1000更大的值。有助于应对网络流量的爆发（当每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目，一般默认值为128）
    - net.core.somaxconn tcp全连接队列

### 3.集群原理

#### 3.1 集群成员关系

Kafka集群依赖zookeeper来维护集群成员信息

- 每个broker都有一个唯一标识符，这个标识符可以在配置文件指定，也可以自动生成
- broker在启动的时候，它果果创建**临时节点**把自己的ID注册到Zookeeper
- Kafka组件订阅Zookeeper的/brokers/ids路径（broker在zookeeper上注册的路径）
- 当有broker加入集群或者退出集群的时候，这些组件就可以获得通知
- 鉴于Zookeeper原理，如果启动另一个相同ID的broker，在Zookeeper上注册会失败
- broker停机、出现网络分区或长时间垃圾回收停顿时，broker会从Zookeeper熵断开连接。这时候注册的临时节点会被从Zookeeper上移除。见银行broker列表的Kafka组件会被告知该broker已经被移除

#### 3.2 控制器

- 就是一个broker，只不过他还负责分区首领的选举
- 通过在zookeeper里创建临时节点 /controller让自己成为控制器。（ 只有一个节点会创建成功 ）
- 每一个broker加入都会有此尝试，控制器已经存在则 在 控制器节点上创建 Zookeeper watch对象，这样他们就可以收到这个节点的变动通知
- 如果控制器被关闭或者与zookeeper断开连接，则Zookeeper上的临时节点会消失，其他节点通过watch对象会得到通知
- 其他节点收到通知后，会尝试创建，进入到类似开始加入时候的控制器节点创建流程，重新选出一个控制器
- 每个新选出的控制器通过Zookeeper的条件递增跳做获得一个全新的、数值更大的controller epoch.
- 其他broker在知道当前controller的epoch之后，如果收到由控制器发出的包含较旧的epoch消息，就会忽略他们

#### 3.3 复制

Kafka使用主题来组织数据，每个主题被氛围若干个分区，每个分区有多个副本。那些副本被保存在broker上。每个broker可以保存成百上千个属于不同主题和分区的副本

副本类型：

- 首领副本
    - 每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本
- 跟随者副本
    - 首领副本意外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求
    - 他们唯一的任务就是从首领副本哪里复制消息，保持与首领一致的状态
    - 如果首领发生峰会，其中一个跟随者会被提升为新首领

副本消息复制

- 跟随者向首领发送获取数据的请求，首领将响应消息发送给跟随者。请求消息里面包含了从副本想要获取的消息的偏移量，而且这些偏移量总是有序的
- 通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度
- 如果跟随者在10s哪没有请求任何消息，或者虽然在请求消息，但是10s内没有请求最新的数据，那么它就会被认为是不同步的。
- 如果一个副本无法与首领保持一致，在首领发生失效时候，他就不可能成为新首领（没包含全部消息）
- 持续请求得到的最新消息副本被称为同步副本，在首领发生失效时，只有同步副本才有可能被选为新首领

首选首领

- 除了当前首领外，每个分区都有一个首选首领----创建主题时选定的首领就是分区的首选首领
- 首选首领：在创建分区时，需要在broker之间均衡首领。因此我们希望首选首领成为真正的首领时，broker间的负载最终会得到均衡
- 默认情况下，Kafka的auto.leader.rebalance.enable为true，它会检查首选首领是不是当前首领，如果不是，并且该副本是同步的，那么就会触发首领选举，让首选首领当选

#### 3.4 处理请求

broker的服务模式

- broker会在他见ring的每一个端口上运行一个Acceptor线程，这个线程会创建一个连接，并把它交给Processor线程去处理。
- Processor线程（也被叫做网络线程）的数量是可以配置的
- 网络线程负责从客户端获取请求消息，把它们放进请求队列，然后从响应队列获取响应消息，把他们发送给客户端
- 请求消息被放到请求队列后，IO线程 会负责处理他们

处理的副本：

- 生产请求和获取请求都必须发送给分区的首领副本
- 特定分区请求发送到非分区首领所在的broker上，客户端或得到一个错误响应。Kafka客户端需要自己负责把生产请求和获取请求发送到正确broker上

元数据请求

- 元数据请求包含了客户端感兴趣的主题列表
- 服务端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本，以及那个副本是首领
- 元数据请求可以发送给任意一个broker，因为所有broker都缓存了这些消息
- 一般来说，客户端会缓存这些消息，并定期通过发送元数据请求来刷新这些信息，从而指知道数据是否发生了变更
- 如果客户端收到"非首领"错误，他会在尝试重发请求之前先刷新元数据

生产请求

- 包含首领副本的broker在收到生产请求的时候，会对请求做一些验证
    - 发送数据的用户是否有主题的写入权限
    - 请求里包含的acks值是否有效果（0，1，all）
    - 如果acks=all,是否有足够多的同步副本保证消息已经被安全写入
- 之后消息写入本地磁盘**注意文件系统缓存**
    - 在Linux系统上，消息会被写到文件系统缓存里面，并不找正他们何时会被刷新到磁盘上
    - Kafka不会一直等待数据被写到磁盘上----它依赖复制功能来保证消息的持久性

获取请求

- 客户端请求要先达到执行的分区首领上，然后客户端通过检查元数据来确保请求的路由是正确的。
- 首领在收到请求时，会先检查请求是否有效
    - 比如，制定的偏移量在分区上是否存在
    - 如果客户端请求的是已经被删除的数据，或请求的偏移量不存在，那么broker将返回一个错误
- 如果请求偏移量存在，broker将按照客户端指定的数量上限从分区里面读消息，再把消息返回给客户端
    - 客户端除了设置消息数据上限，也可以设置下限，在数据积累到下限之后再发送给客户端（配合超时时间一起使用）
- 并不是所有保存在首领分区熵的数据都可以被客户端读取到
    - 大部分客户端只能读取到已经被写入所有同步副本的消息
    - 这是为了保证崩溃一致性
- Kafka使用 **零拷贝** 技术向客户端发送消息
    - Kafka直接把消息从文件（或者更确切的说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区

####                                                                     

#### 2.2

#### 2.3 操作系统调优

### 简单的安装使用

使用docker-compose安装

先定义 docker-compose.yml

```yaml
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka
    depends_on: [ zookeeper ]
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.18.0.3
      KAFKA_CREATE_TOPICS: "test:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /data/product/zj_bigdata/data/kafka/docker.sock:/var/run/docker.sock
```

在docker-compose.yml文件所在的目录进行服务运行

```shell
docker-compose up -d
```

docker启动之后进行测试，先进入容器内部

```shell
docker exec -it kafka_kafka_1 bash
```

在容器内执行测试

```shell
# 创建一个topic
$KAFKA_HOME/bin/kafka-topics.sh --create --topic test --partitions 4 --zookeeper kafka_zookeeper_1:2181 --replication-factor 1

# 查看topic信息
$KAFKA_HOME/bin/kafka-topics.sh --zookeeper kafka_zookeeper_1:2181 --describe --topic test

# 生产者
$KAFKA_HOME/bin/kafka-console-producer.sh --topic=test --broker-list kafka_kafka_1:9092

## 另开一个进程进入容器执行消费测试
$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server kafka_kafka_1:9092 --from-beginning --topic test

```
