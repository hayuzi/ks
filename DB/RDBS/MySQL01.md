MySQL数据库
==

> 参考资料 《MySQL实战45讲》、《深入浅出MySQL》、《高性能MySQL》等

## 1. 数据表设计

### 1.1 三大范式
- 第一范式（原子性）: 数据表中每列必须是不可拆分的最小单元
- 第二范式（唯一性）: 非主键列完全依赖于主键,而不能是依赖于主键的一部分
- 第三范式（独立性）: 非主键列只依赖于主键,不依赖于其他非主键

### 1.2 反范式
- 在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。
- 事实上我们经常会为了性能而妥协数据库的设计。

### 1.3 其他思考
- 主键自增: 如果不设置主键，InnoDB会选择一个唯一键作为主键、如果没有唯一键，会生成一个隐式主键
- 字段not null:  null会占用更多字节，且在程序中造成很多和预期不符合的情况


## 2. 数据类型问题

### 2.1 整数类型

#### 类型介绍
- 包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数
- 何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数

#### 长度
- 整数类型可以被指定长度，例如：INT(11)表示长度为11的INT类型。 每个类型占用空间是固定的（和展示长度无关）
- 长度在大多数场景是没有意义的，它不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。

### 2.2 实数类型
#### 类型介绍
- 包括FLOAT、DOUBLE、DECIMAL
- DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。
- 而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。
- FLOAT类型数据可以存储至多8位十进制数，并在内存中占4字节。
- DOUBLE类型数据可以存储至多18位十进制数，并在内存中占8字节。
- 计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。

### 2.3 字符串类型
#### 类型介绍
- 包括VARCHAR、CHAR、TEXT、BLOB

#### VARCHAR
- VARCHAR用于存储可变长字符串，它比定长类型更节省空间
- VARCHAR使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示。
- VARCHAR存储的内容超出设置的长度时，内容会被截断

#### CHAR
- CHAR是定长的，根据定义的字符串长度分配足够的空间。
- CHAR会根据需要使用空格进行填充方便比较。
- CHAR适合存储很短的字符串，或者所有值都接近同一个长度。
- CHAR存储的内容超出设置的长度时，内容同样会被截断。

#### 使用策略
- 对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR不容易产生碎片
- 对于非常短的列，CHAR比VARCHAR在存储空间上更有效率
- 使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存
- 尽量避免使用TEXT/BLOB类型，查询时会使用临时表，导致严重的性能开销。【其他自己扩展】

### 2.4 枚举类型（ENUM）

#### 类型描述
- 把不重复的数据存储为一个预定义的集合。
- 有时可以使用ENUM代替常用的字符串类型。
- ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。
- ENUM在内部存储时，其实存的是整数。
- 尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。排序是按照内部存储的整数

### 2.5 日期和时间类型
#### 类型描述
- 尽量使用timestamp，空间效率高于datetime
- datetime占用8个字节，时间范围从1000-01-01 00:00:00 ~ 9999-12-31 23:59:59
- TIMESTAMP 4个字节， 时间范围1980-01-01 00:00:01 UTC ~ 2040-01-19 03:14:07 UTC 
- 用整数保存时间戳通常不方便处理。如果需要存储微妙，可以使用bigint存储。


## 3. sql运行原理

### 3.1 执行过程
- 客户端--连接器--(查询缓存)--分析器--优化器--执行器-存储引擎

### 3.2 Server层
#### 包含的功能
- Server层包括连接器、查询缓存、分析器、优化器、执⾏器等，涵盖MySQL的⼤多数核⼼服务功能
- 以及所有的内置函数（如⽇期、时间、数学和加密函数等）
- 所有跨存储引擎的功能都在这⼀层实现，⽐如存储过程、触发器、视图等

#### 连接器
- 管理连接以及权限验证

#### 查询缓存
- 命中则直接返回结果
- 你可以将参数query_cache_type设置成 DEMAND，这样对于默认的SQL语句都不使⽤查询缓存
- MySQL 8.0开始删除了查询缓存功能

#### 分析器
- 词法分析，语法分析
- 列不存在也会在此处报错

#### 优化器
- 执行计划生成、索引选择

#### 执行器
- 也会验证个表T有没有执⾏查询的权限
- 操作引擎，返回结果

### 3.3 存储引擎
#### 功能描述
- 不同引擎共用server层
- 存储数据、提供读写接口
- 存储引擎模式是插件式的
- MySQL中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现

#### 有哪些
- InnoDB
- - 支持ACID事务、行级别锁、MVCC、外键
- - 它的设计的目标就是处理大数据容量的数据库系统
- - 它从MySQL 5.5.5版本开始成为了默认存储引擎
- MyISAM
- - (原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。
- Memory
- - 所有的数据都在内存中，数据的处理速度快，但是安全性不高。
- Archive等等

#### MyISAM与InnoDB区别
- 存储结构
- - MyISAM 每张表被存放在三个文件：frm-表格定义、MYD(MYData)-数据文件、MYI(MYIndex)-索引文件
- - InnoDB 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件）
- - InnoDB表的大小只受限于操作系统文件的大小，一般为2GB
- 存储空间
- - MyISAM可被压缩，存储空间较小
- - InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引
- 可移植性、备份及恢复
- - 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作
- - 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了
- 文件格式
- - MyISAM 数据和索引是分别存储的，数据.MYD，索引.MYI
- - InnoDB 数据和索引是集中存储的，.ibd
- 记录存储顺序
- - MyISAM 按记录插入顺序保存
- - InnoDB 按主键大小有序插入
- 外键与事务
- - MyISAM都不支持，InnoDB支持
- 锁支持
- - MyISAM表级别锁，InnoDB支持行级锁、表级别锁，锁定力度小、并发能力高
- 索引实现方式
- - B+树索引，myisam 是堆表； B+树索引，Innodb 是索引组织表
- - MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据
- - InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
- - InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
- - InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效
- 哈希索引、全文索引
- - InnoDB支持自适应hash索引，不支持全文索引
- - MyISAM支持全文索引、不支持哈希索引

### 3.4 InnoDB引擎的关键特性
#### 3.4.1 插入缓冲（insert buffer）

##### Insert Buffer
- 行记录在自增主键索引的插入是顺序的，但是在辅助索引并不是。这种辅助索引索引页的离散随机读取会导致插入操作性能插入下降
- InnoDB缓冲池中有Insert Buffer信息，但是Insert Buffer和数据页一样，也是物理页的一个组成部分
- 对于非聚集索引的插入或者更新操作，不是每一次直接插入到索引页中，而是先判定插入的非聚集索引页是否在缓冲池中，若在则直接插入；
- 如不在则先放入到 Insert Buffer中。然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge操作
- 这时通常能将多少插入合并到一个操作中(因为在一个索引页中), 这就大大提高了对于非聚集索引的性能
- Insert Buffer的使用必须同时满足两个条件。1. 索引是辅助索引；2. 索引不是唯一的（不需要经过离散读取的索引页唯一性查找）
- Insert Buffer存在的问题：在写密集的情况下、插入缓冲会占用过多的缓冲池内存（innodb_buffer_pool）
- 默认最大可以占用到1/2的缓冲池内存,Percona发布一些patch来修正这个情况。 可以修改IBUF_POOL_PER_MAX_SIZE的值为x, 代表最大只能使用缓冲池内存的1/x

##### Change Buffer
-  InnoDB从1.0.x版本开始引入了Change Buffer。对DML操作-insert、delete、update都进行缓冲。分别是：Insert Buffer、Delete Buffer、Purge Buffer。
- Change Buffer使用的对象依然是非唯一的辅助索引
- 对一条记录进行update操作可能分为两个过程:1.将记录标记为已删除;2.真正将记录删除。
- 因此delete Buffer对update操作的第一个过程，Purge Buffer对应update操作的第二个过程
- 可以通过参数innodb_change_buffering来开启各种Buffer的选项。该参数的可选值有:inserts、deletes、purges、all、none。
- - changes表示启用inserts和deletes，all表示启用所有，none表示都不启用。默认all
- 在InnoDB 1.2.x还可以通过参数innodb_change_buffer_max_size(百分比)来控制最大使用的内存数量

##### Merge Insert Buffer
- 发生merge的场景
- - 1.辅助索引页被读取到缓冲池时;
- - 2.Insert Buffer Bitmap页追踪到该辅助索引页页无可用空间;
- - 3.Master Thread; 在Master Thread线程中每秒或每10秒进行一次Merge Insert Buffer的操作

#### 3.4.2 二次写（double write）
- 对页面拷贝副本，提高数据页的可靠性，当写失效时，通过副本页还原原页，再进行redo
- doublewrite由 内存中的doublewrite buffer (2MB) 和物理磁盘上共享表空间中连续的128个页，即两个区（2MB)组成

#### 3.4.3 自适应哈希索引（ahi）
- 如果建立哈希索引的检索速度比B+树检索的速度快，则建立哈希索引 AHI。
- AHI 有如下要求：对页面的访问模式（长训的条件）必须是一样的
- 哈希索引只能用来等值查询，不能用来做范围查询。

#### 3.4.4 异步IO
- AIO 用户可以连续发送多条IO请求，不需要等待其执行结果，直到所有请求都发送完成了再等待结果。另外可以将多个IO合并成一个IO。
- InnoDB提供内核级别的AIO支持，成为Native AIO。启用Native AIO, 恢复速度提升75%。
- 在InnoDB存储引擎中，read ahead方式的读取都是通过AIO完成，脏页的刷新，也是通过AIO完成。

#### 3.4.5 刷新紧邻页
- 工作原理：当刷新一个脏页时，InnoDB存储引擎会检测该页所在的区（extent)的所有项，如果有脏页，则一起刷新。
- 这样做的好处是通过AIO可以将多个IO写操作合并为一个IO操作。该工作机制在传统机械磁盘下有显著优势
- 这些特性为InnoDB存储引擎带来了更好的性能、更高的可靠性。


## 4. redo log以及binlog

### 4.1 WAL（Write Ahead Logging）
- 先写日志（redolog）再写磁盘不忙时候再写账本
- binlog是server层的日志（归档日志），binlog日志是逻辑日志、binlog日志可以追加写入
- redo log是InnoDB引擎特有的，redo log 是物理日志，redo log是循环写的，空间固定会⽤完

### 4.2 binlog三种格式
#### statement
- statement模式下,记录单元为语句，每一条会修改数据的sql都会记录在binlog中
- 不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能
- 由于sql的执行是有上下文的,因此在保存的时候需要保存相关的信息
- 同时还有一些使用了函数之类的语句无法被记录复制

#### row
- row级别下,记录单元为每一行的改动，基本是可以全部记下来
- 由于很多操作,会导致大量行的改动(比如alter table),因此这种模式的文件保存的信息太多,日志量太大
- 新版的MySQL中对row级别也做了一些优化,当表结构发生变化的时候,会记录语句而不是逐行记录.

#### mixed
- 一种折中的方案,普通操作使用statement记录,当无法使用statement的时候使用row

### 4.3 binglog写入机制
事务执行过程中写到binlog cahce，事务提交时候，再把binlog cache写到binlog文件

####  write 和fsync的时机，是由参数sync_binlog控制
- write指的就是指把⽇志写⼊到⽂件系统的page cache
- 每个线程都有自己的binlog cache 但是共用一份binlog

#### sync_binlog配置
- 0表示每次提交事务都只weite不fsync
- 1表示每次提交事务都会fsync
- N（N>1），表示每次提交事务都write，但积累N个事务后才fsync

### 4.4 redolog写入机制
事务执行过程中，先写入redo log buffer

#### redo log三种状态
- 存在 redo log buffer内存中，物理上是在 mysql进程内存中
- 写到磁盘write 但是没有持久化fsync，物理上是在文件系统的page_chage
- 持久化到磁盘，对应的是hard disk
- InnoDB有⼀个后台线程，每隔1秒，就会把redo log buffffer中的⽇志，调⽤write写到⽂件系统的 page cache，然后调⽤fsync持久化到磁盘。一个没提交的事务的redo log也可能已经持久化到磁盘了

#### innodb_flush_log_at_trx_commit参数
- 0 表示每次事务提交都只把redo log留在redo log buffer中
- 1 表示每次事务提交都把 relo log直接持久化到磁盘
- 2 表示每次事务提交时都只是把 redo log 写到page cache

#### sync_binlog 与 innodb_flush_log_at_trx_commit参数 双1配置
- 正常线上推荐双1配置
- 非双1场景 
- - 业务高峰期、备库复制延迟、⽤备份恢复主库的副本、批量导入数据
- - ⼀般情况下，把⽣产库改成“⾮双1”配置，是设置innodb_flflush_logs_at_trx_commit=2、 sync_binlog=1000。

### 4.5 日志逻辑许序列号与组提交

#### 日志逻辑序列号 log sequence number ， LSN
- LSN单调递增，对应redo_log的一个个写入点，每次写入长度为lenght的redo log，LSN的值就会加上length
- LSN也会写到InnoDB的数据⻚中，来确保数据⻚不会被多次执⾏重复的redo log

#### 组提交（group commit）
- 多事务时，leader事务提交写盘的时候会带LSN，将LSN低于写入值的都持久化到磁盘，这时候其他相关事务就可以直接返回不需要重复操作

### 4.6 更新两阶段提交

#### 更新流程
- 1. 取id=1的行，在内存直接返回，不在则从磁盘读入内存 
- 2. 将行的c字段值加1，写入新行， 新行更新到内存
- 3. 写入 redo log，此时redo log 处于prepare阶段
- 4. 写入 binlog
- 5. 提交事务，将redo log改成commit状态

#### 崩溃恢复
- 处于3-4阶段崩溃，恢复之后会回滚
- 处于4-5阶段崩溃
- - 恢复之后会如果redo log里事务是完成的，则直接提交；
- - 如果redo log里的事务只有完成的prepare，则通过binlog记录判断是回滚还是提交
- - binlog有完整格式
- - - redo log和 binlog有共同的数据字段 XID

### 4.7 binlog分析
可以使用 mysqlbinlog 命令分析 binlog日志文件


## 5. 数据库事务

### 5.1 事务特性

#### ACID特性
- A=Atomicity 原子性
- - 要么全部成功、要么全部失败
- C=Consistency 一致性
- - 系统(数据库)总是从一个一致性的状态转移到另一个一致性的状态,不会存在中间状态
- I=Isolation 隔离性
- -  通常来说:一个事务在完全提交之前,对其他事务是不可见的
- D=Durability 持久性
- - 一旦事务提交,那么就永远是这样子了,哪怕系统崩溃也不会影响到这个事务的结果

### 5.2 隔离级别基础

#### 定义多种隔离性原因
- 事务隔离的不同程度，实际上是通过不同的上锁要求来控制事务并发的能力。所以谈论事务隔离的时候，我们首先要想到“锁”和“并发”。
- 上锁最严格，则意味着事务之间隔离性性越好，效率最低，但是自然也是最安全的。
- 上锁要求宽松，不仅减少了锁的开销，也提升了事务并发的能力，但是也增大了死锁的概率，以及并发带来的不可重复度、脏读和幻读等问题

#### 基于锁的事务隔离级别
- 一般我们说的事务隔离级别都是基于锁的实现方式。这说明也存在无锁的事务并发控制，这是另外的一种事务隔离性，后面会说。

### 5.3 低隔离级别问题

#### 脏读(Dirty Read)：
- 一个事务单元A的读操作读到了另一个未提交的事务单元B写入的数据（其他事务可能回滚，看到的数据则不准确）。

#### 不可重复读取(Non-Repeatable Read): 
- 一个事务单元中两次读同一行数据，这两次读到的数据不一样。（不可重复读重点是修改，同一个事务中再次读取发现值不同）
- 在基于锁的并发控制中“不可重复读”现象发生在当执行SELECT 操作时没有获得读锁或者SELECT操作执行完后马上释放了读锁；
- 多版本并发控制中当没有要求一个提交冲突的事务回滚也会发生“不可重复读”现象。

#### 幻读(Phantom Read)：
- 幻读主要指1个事务单元针对同一个范围的两次SELECT结果不同。存在不可重复读的问题一般也必然存在幻读问题了。
- 区别不可重复读，幻读主要指范围select时由于隔离性原因造成的执行结果不同。
- “幻读”是不可重复读的一种特殊场景：当事务1两次执行SELECT ... WHERE检索一定范围内数据的操作中间，事务2在这个表中创建了(如INSERT)了一行新数据，这条新数据正好满足事务1的“WHERE”子句
- 幻读的重点在与新增，其他事务新增导致本事务查询数据多出来了

#### 更新丢失：
- 两个事务单元都同时更新一行数据，一个事务单元对数据的更新把另一个事务单元对数据的更新覆盖了。
- 这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来

### 5.4 隔离级别具体类型

#### 重要说明
- 下面讨论的四种隔离级别是由ANSI/ISO SQL定义的标准。

#### 未提交读(read uncommitted)
- 小总结：读锁、写锁，处理好一条记录均马上释放，还没有范围锁。事务间完全没隔离，所有问题均可能出现
- 读未提交是指，⼀个事务还没提交时，它做的变更就能被别的事务看到。 可能会导致脏读、幻读、或不可重复读

#### 已提交读(read committed)
- 小总结：读已提交，读锁SELECT后马上释放，没有范围锁，写锁一直保持到事务结束，会不可重复读，当然也包括幻读
- 其他事务只能读取到本事务已经提交的部分，有不可重复读问题
- Oracle等多数数据库默认都是该级别 (不重复读)， MySQL的InnoDB引擎不是
- MySQL的InnoDB的区别
- - 一般情况下只有行锁，没有间隙锁部分
- - 为了解决数据和日志不一样问题，可以使用该隔离级别加binlog格式设置为row
- MySQL实际使用
- - 但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。
- - 这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。
- - 可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181）
- - 所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。
- - 这种情况同样适用于MySQL的默认隔离级别RR。

#### 可重复读(repeatable read)
- 小总结：可重复读，一个事务内读写锁全部保持到事务结束，缺少范围锁，会有幻读
- 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生
- InnoDB用间隙锁解决幻读问题(Gap Lock)
- - 跟间隙锁存在冲突关系的，是 "往这个间隙中插⼊⼀个记录" 这个操作
- - 间隙锁和⾏锁合称next-key lock，每个next-key lock都是前开后闭区间
- InnoBD引擎中
- - InnoDB引擎默认使用该隔离级别
- - InnoDB在该隔离级别下使用了间隙锁来解决幻读的问题
- innodb自动使用间隙锁的条件
- - InnoDB 间隙锁只在可重复读的隔离级别下存在 
- - 检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加）
- 间隙锁加锁规则
- - 原则一 加锁基本单位是next-key lock
- - 原则二 查找过程中访问到的对象才会加锁
- - 优化一 索引上的等值查询，给唯⼀索引加锁的时候，next-key lock退化为⾏锁；
- - 优化二 索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key lock退化为间隙锁 
- - ⼀个bug：唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌

#### 可序列化(serializable )
- 要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。范围锁也持续到事务结束（纯锁机制下）
- 小总结：可序列化，一个事务内读写锁全部保持到事务结束，并且存在范围锁
- 可序列化不同事务之间完全隔离，针对同一行记录的读写不会并行，不会有隔离级别低带来的问题。但并发性能会极速下降

### 5.5 隔离级别查看修改

#### 查看
- 通过查询数据库提供的系统变量 tx_isolation 或 transaction_isolation 的值即可获取当前的事务隔离级别
- 使用如下命令   show variables like "%tx_isolation%";  
- SELECT @@global.tx_isolation; //查询全局事务SELECT @@session.tx_isolation; //查询当前会话事务

#### 修改
- 使用 set session transaction isolation level read commit;   （设置当前会话的隔离级别）
- 使用 set global transaction isolation level read commit;   （设置全局会话的隔离级别，不会影响当前已经打开其他的会话）
- 通过命令 set transaction isolation level 可设置下一次事务操作的隔离级别，该设置会随着下一次事务的提交而失效

### 5.6 MVCC多版本并发控制

#### 锁机制
InnoDB实现了行锁、页锁、表锁

##### 根据读写
- 共享锁（读锁，可以加多个）
- 排他锁（写锁，只可以加一个）

##### 两阶段锁协议
- 必要性
- - 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）
- - 这种方式虽然无法避免死锁，但是两段锁协议可以保证事务的并发调度是串行化（串行化很重要，尤其是在数据恢复和备份的时候）的。
- 加锁阶段：
- - 在该阶段可以进行加锁操作。
- - 在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），
- - 在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。
- - 加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。
- 解锁阶段：
- -  当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。

##### 根据锁范围
- 全局锁
- - 全局锁的典型使⽤场景是，做全库逻辑备份
- - 命令:  Flush tables with read lock (FTWRL)
- 表级别锁
- - 表锁和元数据锁(MDL)
- - - 访问表的时候会自动 MDL（保证读写正确性）
- - - 逻辑备份时候遇到binlog的DDL语句后流程
- - online DDL
- - - 三种方式以及坑
- 行级别锁
- - 两阶段锁协议
- - - InnoDB 行锁在需要的时候才加，等事务结束才释放
- - - 业务处理时候： 如果事务要锁多行，要把最可能造成冲突与影响并发的锁尽量后置
- 间隙锁
- - InnoDB 关闭间隙锁
- - - 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock）
- - - A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

##### 死锁和死锁检测

死锁解决
- 等待与超时
- - InnoDB的innodb_lock_wait_timeout默认配置是 50s
- 主动检测与回滚
- - 热点行更新导致死锁、 死锁检测耗费大量的cpu资源
- - 临时关闭死锁检测(极度不推荐)、控制并发度
- - 业务设计上拆解热点行为多条记录

死锁业务解决方案
- 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会
- 例子：两个账户同时操作，如果是交叉更新，遇到并发会死锁。如果按照固定顺序，比如主键大小来排序更新，则可以降低死锁概率
- 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率
- 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率


#### InnoDB的MVCC
是通过在每行纪录后面保存两个隐藏的列来实现的，
隐藏列保存行的创建版本号以及过期（删除）版本号。
每次更新都会记录回滚操作，回滚日志在不需要的时候会删除，回滚日志影响长事务效率。
每开始一个新的事务，系统版本号都会自动递增。

##### 快照读 / 当前读
- 快照读（搜索时时候不会加锁）
- - 一般的 select * from ... where ...  查询语句都是快照读
- 当前读（会在搜索的时候加锁）
- - select * from ... where ... for update
- - elect * from .... where ... lock in share mode
- - update .... set .. where ...  与 delete from. . where ..

##### undo log
- 定义
- - undo log主要记录数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚
- 存储位置
- - 在InnoDB存储引擎中，undo log存储在回滚段(Rollback Segment)中
- - 每个回滚段记录了1024个undo log segment，而在每个undo log segment段中进行undo 页的申请
- - 在5.6以前，Rollback Segment是在共享表空间里的
- - 5.6.3之后，可通过 innodb_undo_tablespace设置undo存储的位置
- undo log的写入时机
- - DML操作修改聚簇索引前，记录undo log
- - 二级索引记录的修改，不记录undo log
- 作用
- - 事务回滚
- - MVCC
- 与redo log对比
- - undo log是逻辑日志，对事务回滚时，只是将数据库逻辑地恢复到原来的样子
- - 而redo log是物理日志，记录的是数据页的物理变化，显然undo log不是redo log的逆过程

##### MVCC流程
- 开始事务
- 记录数据行数据到undo log（未考虑redo log）
- 更新数据
- undo log写到磁盘
- 将数据写入磁盘
- 提交事务

### 5.7 事务启动方式
- 显式声明 begain commit
- set autocommit=0

## 6. 索引原理

### 6.1 B+树

#### 基于多路平衡查找树
- 专门为了外存储设备设计的
- 磁盘读取以块为单位，同块数据会一次性读取
- 存储引擎页概念（磁盘管理的最小单位）、InnoDB引擎默认每个页大小为16k
- 每个多路平衡查找树的节点占用一个磁盘块或页空间，可以减少IO次数
- 节点数据页的分页与合并
- InnoDB存储引擎设计时根节点常驻内存

#### 叶子结点存记录
- 聚簇索引
- - InnoDB引擎的主键索引，叶子节点存数据记录
- 非聚簇索引
- - 其他索引，叶子节点存主键
- B+树的叶子节点使用指针顺序连接在一起

#### 扩展知识（B*树）
- B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；
- B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）。
- MySQL未使用该组织方式
- - 但是每条数据的插入与删除都会影响到多层级节点的前后指针，这会有一部分管理难度 以及 性能消耗

#### MySQL8.0 引入函数索引

内部是依据虚拟列来实现的
- 虚拟列不存储在数据行中，但虚拟列的元数据信息会存在于相关系统表中，对虚拟列的添加或者删除只会涉及这些系统表，不会导致数据表的重建，所以效率很高
- 需要注意，不能建立虚拟列和真实列的联合索引

### 6.2 Hash索引

#### Hash表
- 不适合做范围查询，而且数据不一定均衡

#### InnoDB自适应hash索引
- InnoDB用户无法手动创建哈希索引，这一层上说，InnoDB确实不支持哈希索引 
- InnoDB会自调优(self-tuning)，如果判定建立自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB自己会建立相关哈希索引，这一层上说，InnoDB又是支持哈希索引的

#### 自适应hash索引原理
- 在MySQL运行的过程中，如果InnoDB发现，有很多SQL存在很长的寻路，并且有很多SQL会命中相同的页面(page)，
- InnoDB会在自己的内存缓冲区(Buffer)里，开辟一块区域，建立自适应哈希索引AHI，以加速查询
- 从这个层面上来说，InnoDB的自使用哈希索引，更像“索引的索引”，毕竟其目的是为了加速索引寻路

#### 开启自适应hash的影响
- 既然是哈希，key是索引键值（或者键值前缀）。value是索引记录页面位置。
- 系统自己判断“应该可以加速查询”而建立的，不需要用户手动建立，故称“自适应”。
- 不是一定能加速，有时候会误判。
- - 很多单行记录查询（例如passport，用户中心等业务）索引范围查询,（此时AHI可以快速定位首行记录）所有记录内存能放得下
- hash自适应索引会占用innodb buffer pool

### 6.3 表索引优化与分析

#### 索引覆盖查询
- 非索引覆盖会再次回表查询提取数据

#### 创建索引考虑的因素
- 常用来查询排序的字段、且区分度比较大的
- 联合索引查询排序（最左前缀原则）
- 联合索引以及单索引同时需求的时候考虑空间原则

#### 索引下推 （index condition pushdown ）简称ICP
- mysql5.6做的回表查询优化

在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，
然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。

索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数

#### 索引使用以及MySQL的慢SQL分析
- explain关键字

#### 索引失效问题（没用到）
- 不等于查询、列运算、like、全表扫描更快、联合索引顺序错误
- 函数计算
- - 破坏了有序性，优化器会放弃走树搜索功能，有可能选择遍历主键索引或者遍历普通索引
- 隐式类型转换
- - int和字符串类型对比会转int再比较
- 隐式字符编码转换
- - 同为字符串的按照数据长度增加方向进行转换(如 utf8--urf8mb4)
- - 关联查询中，如果解析后查询字段是utf8而给定的值是utf8mb4的，则会相当于在查询字段上加了转换函数
- - 查询字段是utf8mb4的，给的值是utf8，则类似于值上加函数，如此才能用上索引

#### 查询慢问题排查

##### 长时间不返回数据
- 等待MDL锁
- - show processlist找到持有MDL锁（ 显示状态为sleep）的进程并kill
- - 借助performance_schema和sys系统库
- - - （MySQL启动时需要设置performance_schema=on，相比off会有10%性能损失）
- - - select bloking_pid from sys.schema_table_lock_waits  可以直接找出造成阻塞的process id， 把这个连接⽤kill 命令断开即可
- 等待 flush
- - flush tables [t] with read lock; (t可以不加, 不加表示是flush所有表)
- 等 行锁
- - 读取数据要加读锁，如果有事务一直持有写锁并不提交，就会阻塞

##### 查询慢
- 一致性读
- - 查询时候遇到其他事务行锁重复大量更新单条记录，一致性读回查询undo log造成时间损耗
- 当前读
- - 带lock in share mode的SQL语句，是当前读，可以立即返回数据，不过这已经是更新后的数据

### 6.4 创建索引的要点

#### 创建索引注意
- 索引字段应该指定为NOT NULL，在MySQL中，含有空值的列很难进行查询优化，因为他们使得索引、索引的统计信息以及比较运算更加复杂
- 取值离散大的字段：
- 索引字段越小越好

#### 索引重建
- 删除数据库索引不一定会释放，需要定期重建优化
- 可以使用ALTER TABLE t engine=InnoDB的方式重建索引

### 6.5 排序功能

#### 按照线程分配 sort_buffer 内存

##### sort_buffer_size
- 如果sort_buffer_size小于要排序的数据量，则会利用磁盘临时文件辅助

##### 全字段排序
- 如果内存足够，就尽量多利用内存，mysql会优先选择全字段排序，不用重复回表取取数据

##### rowid排序
- max_length_for_sort_data 控制最长排序的⾏数据，如果mysql 认为单行太大，可能切换为rowid排序

#####  内存临时表
- 随机排序
- - mysql创建临时表，并使用 memory引擎
- - 扫描表从表中取出排序字段值，并用rand()函数生成一个大于0小于1的随机数，并把随机消暑和word分别存入临时表R和W字段
- - 按照R排序，初始化 sort_buffer，sort_buffer中有两个字段，一个double类型，一个整型
- - 从内存临时表中全表扫表，一行行取出R值和位置信息，分别存入sort_buffer中的两个字段
- - sort_buffer中根据R值排序，排序完成后，取出前三个结果的位置信息，依次从内存临时表中取出查询值并返回给客户端

##### tmp_table_size 配置
- 限制内存临时表的大小，如果临时表超过该值，那么内存临时表会转为磁盘临时表

##### 磁盘临时表
- 磁盘临时表默认引擎是 InnoDB
- 优先队列排序算法
- - MySQL 5.6版本引入的一个新的排序算法（临时文件算法是归并排序）
- - 需要维护的堆大小如果超出 sort_buffer_size的限制，则会进入磁盘排序，否则可以使用优先队列排序算法

#### 默认排序

##### 基础规则
- MySQL查询数据的时候，默认是按照获取数据的顺序排序
- 所以，在某些情况下，不加 order by 查询出来的数据可能是主观认为的乱序

##### 异常场景
- 如果一个表只有一个主键以及一个设置为索引的字段，我们查询 select *的时候，发现按照 非主键字段排序了
- explain分析结果显示，该语句走了非主键的索引覆盖查询，而不是主键全表扫描。默认使用了非主键的索引字段中读取出来的数据排序

### 6.6 主键自增

#### 自增值机制
- InnoDB引擎的⾃增值，其实是保存在了内存⾥，并且到了MySQL 8.0版本后，保存在redo log
- 从auto_increment_offset开始，以auto_increment_increment为步 ⻓，持续叠加，直到找到第⼀个⼤于X的值，作为新的⾃增值。
- 修改自增值处于插入流程中，数据传入并填充自增ID之后，实际插入数据之前，因此，在实际插入数据失败时，自增值已经变更，并不会回退
- 自增锁: 批量插入数据时会以依次递增的方式申请自增锁，从1开始，每次申请数量都是上次的两倍，如果遇到并发插入，就可能跳过已经存在的ID

#### 主键不连续情况
- 唯一键冲突
- 事务回滚
- 自增锁批量插入批量申请跳过已存在ID



