Redis实践
==

## 1. 业务实践问题

### 1.1 缓存雪崩、穿透、击穿

#### 缓存穿透
基本含义
- 缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空
- 如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统

解决方案
- 返回空对象
- - 当缓存未命中，查询持久层也为空，可以将返回的空对象写到缓存中
- - 为了避免存储过多空对象，通常会给空对象设置一个过期时间 
- 问题
- - 如果有大量的key穿透，缓存空对象会占用宝贵的内存空间
- - 空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。

扩展：布隆过滤器
- 布隆过滤器是一种空间效率高的概率型数据结构。布隆过滤器专门用来检测集合中是否存在特定的元素
- 布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中
- 布隆过滤器适用场景：爬虫系统url去重、垃圾邮件过滤、黑名单

#### 缓存并发与击穿
缓存击穿含义
- 热点数据集中高并发访问，失效瞬间大量并发访问击穿缓存，直接访问数据库，导致数据库压力骤增，造成大量请求阻塞

解决方案
- 使用互斥锁（mutex key）
- - 这种思路比较简单，就是让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可
- - 同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量
- - 如果是分布式应用就需要使用分布式锁
- 热点数据永不过期
- - 物理不过期，针对热点key不设置过期时间
- - 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建
- - 从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的
- 定时异步刷新等
- - 后台定时异步刷新更新缓存信息，可以保证数据的大部分时候达到要求，数据不一致问题需要考量
- 限流、错峰失效
- - 限制访问的流量，并且根据业务进行错峰失效


#### 缓存雪崩应对
基本含义
- 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机
- 和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

事前解决方案
- - 缓存高可用配置要做好，基础架构需要处理
- - 缓存永不过期：跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存
- - 如果有必要，可以考虑多级缓存（备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存）

事中解决方案
- 本地cache缓存 限流降级
- 加互斥锁，同一事件只让一个线程构建缓存，其他线程阻塞排队

事后解决方案
- Redis持久化，重启快速恢复数据

#### 缓存预热

概念介绍
- 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存
- 如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

操作方法
- 数量不大的时候，工程启动的时候进行加载缓存动作
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存

#### 缓存降级
缓存降级
- 缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。
- 在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力
- 降级一般是有损的操作，所以尽量减少降级对于业务的影响程度

#### 大对象的问题
- 大数据对象清理可以空余更多空间
- 转换成hash等其他分散的小数据存储等



### 1.2 缓存与数据库双写一致性
常用方案
- Cache Aside Pattern（先读缓存后读库并更新、先写库后删缓存）
- 高并发时候延时双删策略（删，写库，延时再删）
- canal消费binlog策略


### 1.3 并发竞争问题

#### 基础思路
- 分布式锁，或者版本号时间戳的乐观锁设计

#### 分布式锁
- set选项使用 nx 与 ex原子执行，防止执行异常而未释放锁
- 独立线程使用UUID作为锁的值，防止因超时而被其他线程释放锁
- 另外使用 原子值判断并删除操作（Lua脚本可以实现）
- 一个简单方法：开启新的线程来做锁续命，防止过早被释放。（java线程 / go可以协程）
- 另外，提高分布式锁的并发性能，可以通过拆分需要锁的数据的数量来实现（比如：100个库存，使用10个10库存的锁 ）

#### 与zookeeper对比
- CAP理论中， redis主要关注 AP ，可用性与分区容错性
- zookeeper主要关注 CP， 一致性与分区容错性
- zookeeper集群中实现的锁，会在半数以上从节点写成功才返回结果，而redis不是

所以在使用redis作为分布式锁实现的时候，需要了解的问题是：
- 集群模式下，高并发场景有可能有不一致的情况出现
- 通常有推荐使用 redLock 方案，或者直接在保证高可用情况下使用单机版 redis 专门做分布式锁


## 2. 其他一些实践

### 2.1 与Memcache的区别

存储方式
- Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小
- Redis有部份存在硬盘上，这样能保证数据的持久性

数据支持类型
- Memcache对数据类型支持相对简单
- Redis有丰富的数据类型

使用底层模型不同
- 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样
- Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求


### 2.2 keys * 与 scan指令

keys命令
- redis 的单线程的。keys 指令会导致线 程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复

scan
- 这个时 候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，
- 但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间 会比直接用 keys 指令长

### 2.3 大量key同时过期问题

该问题原因
- 如果大量的key过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象(因为redis是单线程的)。
- 严重的话可能会导致服务器雪崩

解决方案
- 所以我们一般在过期时间上加一个随机值，让过期时间尽量分散


## 3. 内存相关问题

### 3.1 内存消耗
- 对象内存
- - 存储着所有数据
- 缓冲内存
- - 客户端缓冲 通过参数client-output-buffer-limit
- - 复制积压缓冲区  根据repl-backlog-size参数控制
- - AOF缓冲区 用于在Redis重写AOF文件期间保存最近的写入命令

#### 内存碎片
- 可采用数据对齐和安全重启等方式规避内存碎片的问题


### 内存回收策略
- 惰性删除
- 定时任务删除

### 内存优化
- 缩减键值对象的长度
- 共享对象池
- 字符串优化
- 编码优化（使用ziplist编码能节约内存但是会提高消耗时--空间换时间）

